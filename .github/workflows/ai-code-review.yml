name: AI Code Reviewer

on:
  issue_comment:
    types: [created]

permissions: write-all

jobs:
  ai-code-review:
    if: |
      github.event.issue.pull_request && (
        contains(github.event.comment.body, '/gemini-review') ||
        contains(github.event.comment.body, '/openai-review') ||
        contains(github.event.comment.body, '/claude-review') ||
        contains(github.event.comment.body, '/llama-review')
      )
    runs-on: self-hosted

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Install system dependencies (for llama & build tools)
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential \
            cmake \
            gcc-11 \
            g++-11 \
            python3-dev \
            python3-pip \
            ninja-build

      - name: Set gcc-11 and g++-11 as default compilers
        run: |
          sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-11 100
          sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-11 100

      - name: Verify compilers and cmake
        run: |
          which gcc
          which g++
          gcc --version
          g++ --version
          cmake --version

      - name: Install Python dependencies manually (ensures CC/CXX are respected)
        run: |
          python3 -m pip install --upgrade pip setuptools wheel scikit-build-core
          CC=gcc CXX=g++ CMAKE_ARGS="-DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++" \
          python3 -m pip install --force-reinstall --no-cache-dir -r requirements.txt

      - name: Run AI Code Reviewer Action
        uses: ./ai-code-reviewer
        with:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          CLAUDE_API_KEY: ${{ secrets.CLAUDE_API_KEY }}
          LLAMA_MODEL_PATH: ${{ secrets.LLAMA_MODEL_PATH }}
          LLAMA_CONTEXT_SIZE: ${{ secrets.LLAMA_CONTEXT_SIZE }}
          LLAMA_GPU_LAYERS: ${{ secrets.LLAMA_GPU_LAYERS }}
          LLAMA_SEED: ${{ secrets.LLAMA_SEED }}
          LLAMA_THREADS: ${{ secrets.LLAMA_THREADS }}
          LLAMA_TEMPERATURE: ${{ secrets.LLAMA_TEMPERATURE }}
          LLAMA_TOP_P: ${{ secrets.LLAMA_TOP_P }}
          LLAMA_MAX_TOKENS: ${{ secrets.LLAMA_MAX_TOKENS }}
          LLAMA_REPEAT_PENALTY: ${{ secrets.LLAMA_REPEAT_PENALTY }}
          INPUT_EXCLUDE: "*.md, docs/**, *.json"
        env:
          CC: gcc
          CXX: g++
          CMAKE_ARGS: -DCMAKE_C_COMPILER=gcc -DCMAKE_CXX_COMPILER=g++
